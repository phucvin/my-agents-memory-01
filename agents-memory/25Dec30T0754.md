Summary: Updated the minimal LLM implementation to include a generation prompt for "apple", refactored text generation logic to reduce duplication, implemented random seeding, and added a demo with 10 random starting words (30% from training data).

# User Prompt
run llm_minimal with starting text apple as well and update demo outputs

# Agent Response
I modified `codes/minimal_llm/main.cpp` to include a generation block for the starting text "apple". I then compiled and ran the code, capturing the new output which shows the model attempting to complete the text starting with "apple". Finally, I updated `codes/minimal_llm/README.md` to reflect these changes in the "Example Output" section.

# User Prompt
use random random seed. refactor code to reduce duplication, especially when generating for prompts. and generate for 10 more random starting words, 30% are in words in the training data.

# Agent Response
I modified `codes/minimal_llm/main.cpp` to use `std::random_device` and `time(NULL)` for seeding, ensuring random initialization across runs. I refactored the text generation logic into a `generate_text` helper function to reduce code duplication. I also implemented logic to randomly select 10 starting words (3 from the training data and 7 from a predefined list of other words) and generate text for them. I updated `codes/minimal_llm/README.md` with the new output showing these random generations.
